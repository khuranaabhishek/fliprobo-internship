{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d748250",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30d70420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                                  Video Title  \\\n",
      "0      1                           \"Baby Shark Dance\"   \n",
      "1      2                                  \"Despacito\"   \n",
      "2      3                       \"Johny Johny Yes Papa\"   \n",
      "3      4                                  \"Bath Song\"   \n",
      "4      5                          \"Wheels on the Bus\"   \n",
      "5      6                              \"See You Again\"   \n",
      "6      7                               \"Shape of You\"   \n",
      "7      8                \"Phonics Song with Two Words\"   \n",
      "8      9                                \"Uptown Funk\"   \n",
      "9     10                              \"Gangnam Style\"   \n",
      "10    11  \"Learning Colors ‚Äì Colorful Eggs on a Farm\"   \n",
      "11    12                                     \"Axel F\"   \n",
      "12    13                             \"Dame Tu Cosita\"   \n",
      "13    14   \"Masha and the Bear ‚Äì Recipe for Disaster\"   \n",
      "14    15                        \"Baa Baa Black Sheep\"   \n",
      "15    16                             \"Lakdi Ki Kathi\"   \n",
      "16    17                                      \"Sugar\"   \n",
      "17    18                             \"Counting Stars\"   \n",
      "18    19                                       \"Roar\"   \n",
      "19    20           \"Waka Waka (This Time for Africa)\"   \n",
      "20    21                      \"Shree Hanuman Chalisa\"   \n",
      "21    22          \"Humpty the train on a fruits ride\"   \n",
      "22    23                                      \"Sorry\"   \n",
      "23    24                          \"Thinking Out Loud\"   \n",
      "24    25                                    \"Perfect\"   \n",
      "25    26                                 \"Dark Horse\"   \n",
      "26    27                                 \"Let Her Go\"   \n",
      "27    28                                      \"Faded\"   \n",
      "28    29                             \"Girls Like You\"   \n",
      "29    30                                    \"Lean On\"   \n",
      "\n",
      "                                               Artist  Views  \\\n",
      "0         Pinkfong Baby Shark - Kids' Songs & Stories  15.12   \n",
      "1                                          Luis Fonsi   8.55   \n",
      "2   LooLoo Kids - Nursery Rhymes and Children's Songs   6.95   \n",
      "3                          Cocomelon - Nursery Rhymes   6.85   \n",
      "4                          Cocomelon - Nursery Rhymes   6.56   \n",
      "5                                         Wiz Khalifa   6.40   \n",
      "6                                          Ed Sheeran   6.33   \n",
      "7               ChuChu TV Nursery Rhymes & Kids Songs   6.00   \n",
      "8                                         Mark Ronson   5.33   \n",
      "9                                                 Psy   5.30   \n",
      "10                                        Miroshka TV   5.15   \n",
      "11                                         Crazy Frog   4.78   \n",
      "12                                      Ultra Records   4.74   \n",
      "13                                         Get Movies   4.60   \n",
      "14                         Cocomelon - Nursery Rhymes   4.17   \n",
      "15                                       Jingle Toons   4.13   \n",
      "16                                           Maroon 5   4.09   \n",
      "17                                        OneRepublic   4.05   \n",
      "18                                         Katy Perry   4.03   \n",
      "19                                            Shakira   4.01   \n",
      "20                              T-Series Bhakti Sagar   3.97   \n",
      "21      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   3.89   \n",
      "22                                      Justin Bieber   3.84   \n",
      "23                                         Ed Sheeran   3.79   \n",
      "24                                         Ed Sheeran   3.78   \n",
      "25                                         Katy Perry   3.77   \n",
      "26                                          Passenger   3.70   \n",
      "27                                        Alan Walker   3.67   \n",
      "28                                           Maroon 5   3.65   \n",
      "29                               Major Lazer Official   3.65   \n",
      "\n",
      "          Upload Date  \n",
      "0       June 17, 2016  \n",
      "1    January 12, 2017  \n",
      "2     October 8, 2016  \n",
      "3         May 2, 2018  \n",
      "4        May 24, 2018  \n",
      "5       April 6, 2015  \n",
      "6    January 30, 2017  \n",
      "7       March 6, 2014  \n",
      "8   November 19, 2014  \n",
      "9       July 15, 2012  \n",
      "10  February 27, 2018  \n",
      "11      June 16, 2009  \n",
      "12      April 5, 2018  \n",
      "13   January 31, 2012  \n",
      "14      June 25, 2018  \n",
      "15      June 14, 2018  \n",
      "16   January 14, 2015  \n",
      "17       May 31, 2013  \n",
      "18  September 5, 2013  \n",
      "19       June 4, 2010  \n",
      "20       May 10, 2011  \n",
      "21   January 26, 2018  \n",
      "22   October 22, 2015  \n",
      "23    October 7, 2014  \n",
      "24   November 9, 2017  \n",
      "25  February 20, 2014  \n",
      "26      July 25, 2012  \n",
      "27   December 3, 2015  \n",
      "28       May 31, 2018  \n",
      "29     March 22, 2015  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)\n",
    "table = driver.find_element(By.CLASS_NAME, 'sortable.wikitable.sticky-header.static-row-numbers.sort-under.col3center.col4right.jquery-tablesorter')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    cols = [col.text for col in cols]\n",
    "    if cols:\n",
    "        data.append(cols)\n",
    "df = pd.DataFrame(data)\n",
    "df_clean = df.drop(df.columns[4], axis=1)\n",
    "df_clean.columns = ['Video Title', 'Artist', 'Views', 'Upload Date']\n",
    "pattern = r'\\[\\d+\\]'\n",
    "df_clean['Video Title'] = df_clean['Video Title'].apply(lambda x: re.sub(pattern, '', x))\n",
    "df_clean['Rank'] = pd.Series(range(1, len(df_clean) + 1)) \n",
    "df_clean = df_clean[['Rank', 'Video Title', 'Artist', 'Views', 'Upload Date']]\n",
    "print(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43702891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353e4774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "588f8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eeb7eac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Series  \\\n",
      "0                   ICC Womens T20 World Cup 2024   \n",
      "1                   ICC Womens T20 World Cup 2024   \n",
      "2        Bangladesh Tour of India T20 Series 2024   \n",
      "3     Australia U19 Tour of India Multiday Series   \n",
      "4                   ICC Womens T20 World Cup 2024   \n",
      "5        Bangladesh Tour of India T20 Series 2024   \n",
      "6        Bangladesh Tour of India T20 Series 2024   \n",
      "7                   ICC Womens T20 World Cup 2024   \n",
      "8      New Zealand Tour of India Test Series 2024   \n",
      "9      New Zealand Tour of India Test Series 2024   \n",
      "10     New Zealand Tour of India Test Series 2024   \n",
      "11     India Tour of South Africa T20 Series 2024   \n",
      "12     India Tour of South Africa T20 Series 2024   \n",
      "13     India Tour of South Africa T20 Series 2024   \n",
      "14     India Tour of South Africa T20 Series 2024   \n",
      "15                 Border Gavaskar Trophy 2024-25   \n",
      "16  India Women Tour of Australia ODI Series 2024   \n",
      "17                 Border Gavaskar Trophy 2024-25   \n",
      "18  India Women Tour of Australia ODI Series 2024   \n",
      "19  India Women Tour of Australia ODI Series 2024   \n",
      "20                 Border Gavaskar Trophy 2024-25   \n",
      "21                 Border Gavaskar Trophy 2024-25   \n",
      "22                 Border Gavaskar Trophy 2024-25   \n",
      "23          England Tour of India T20 Series 2025   \n",
      "24          England Tour of India T20 Series 2025   \n",
      "25          England Tour of India T20 Series 2025   \n",
      "26          England Tour of India T20 Series 2025   \n",
      "27          England Tour of India T20 Series 2025   \n",
      "28          England Tour of India ODI Series 2025   \n",
      "29          England Tour of India ODI Series 2025   \n",
      "30          England Tour of India ODI Series 2025   \n",
      "31              India In England Test Series 2025   \n",
      "32         India Women In England T20 Series 2025   \n",
      "33         India Women In England T20 Series 2025   \n",
      "34              India In England Test Series 2025   \n",
      "35         India Women In England T20 Series 2025   \n",
      "36         India Women In England T20 Series 2025   \n",
      "37              India In England Test Series 2025   \n",
      "38         India Women In England T20 Series 2025   \n",
      "39         India Women In England ODI Series 2025   \n",
      "40         India Women In England ODI Series 2025   \n",
      "41         India Women In England ODI Series 2025   \n",
      "42              India In England Test Series 2025   \n",
      "43              India In England Test Series 2025   \n",
      "\n",
      "                                               Places    Date       Time  \n",
      "0          Dubai International Cricket Stadium, Dubai   4 Oct  19:30 IST  \n",
      "1          Dubai International Cricket Stadium, Dubai   6 Oct  15:30 IST  \n",
      "2   Shrimant Madhavrao Scindia Cricket Stadium, Gw...   6 Oct  19:00 IST  \n",
      "3                    M A Chidambaram Stadium, Chennai   7 Oct   9:30 IST  \n",
      "4          Dubai International Cricket Stadium, Dubai   9 Oct  19:30 IST  \n",
      "5                         Arun Jaitley Stadium, Delhi   9 Oct  19:00 IST  \n",
      "6       Rajiv Gandhi International Stadium, Hyderabad  12 Oct  19:00 IST  \n",
      "7                    Sharjah Cricket Stadium, Sharjah  13 Oct  19:30 IST  \n",
      "8                    M Chinnaswamy Stadium, Bengaluru  16 Oct   9:30 IST  \n",
      "9       Maharashtra Cricket Association Stadium, Pune  24 Oct   9:30 IST  \n",
      "10                           Wankhede Stadium, Mumbai   1 Nov   9:30 IST  \n",
      "11                                  Kingsmead, Durban   8 Nov  20:00 IST  \n",
      "12                         St George's Park, Gqeberha  10 Nov  20:00 IST  \n",
      "13                         SuperSport Park, Centurion  13 Nov  20:00 IST  \n",
      "14                The Wanderers Stadium, Johannesburg  15 Nov  20:00 IST  \n",
      "15                               Perth Stadium, Perth  22 Nov   7:50 IST  \n",
      "16                       Allan Border Field, Brisbane   5 Dec   9:00 IST  \n",
      "17                            Adelaide Oval, Adelaide   6 Dec   9:30 IST  \n",
      "18                       Allan Border Field, Brisbane   8 Dec   5:30 IST  \n",
      "19                                 WACA Ground, Perth  11 Dec  11:00 IST  \n",
      "20                                The Gabba, Brisbane  14 Dec   5:50 IST  \n",
      "21                Melbourne Cricket Ground, Melbourne  26 Dec   5:00 IST  \n",
      "22                      Sydney Cricket Ground, Sydney   3 Jan   5:00 IST  \n",
      "23                              Eden Gardens, Kolkata  22 Jan  19:00 IST  \n",
      "24                    MA Chidambaram Stadium, Chennai  25 Jan  19:00 IST  \n",
      "25                      Niranjan Shah Stadium, Rajkot  28 Jan  19:00 IST  \n",
      "26      Maharashtra Cricket Association Stadium, Pune  31 Jan  19:00 IST  \n",
      "27                           Wankhede Stadium, Mumbai   2 Feb  19:00 IST  \n",
      "28       Vidarbha Cricket Association Stadium, Nagpur   6 Feb  13:30 IST  \n",
      "29                          Barabati Stadium, Cuttack   9 Feb  13:30 IST  \n",
      "30                   Narendra Modi Stadium, Ahmedabad  12 Feb  13:30 IST  \n",
      "31                                  Headingley, Leeds  20 Jun  15:30 IST  \n",
      "32                           Trent Bridge, Nottingham  28 Jun  15:30 IST  \n",
      "33                       Seat Unique Stadium, Bristol   1 Jul  15:30 IST  \n",
      "34                              Edgbaston, Birmingham   2 Jul  15:30 IST  \n",
      "35                            Kennington Oval, London   4 Jul  15:30 IST  \n",
      "36                           Old Trafford, Manchester   9 Jul  15:30 IST  \n",
      "37                      Lord's Cricket Ground, London  10 Jul  15:30 IST  \n",
      "38                              Edgbaston, Birmingham  12 Jul  15:30 IST  \n",
      "39                         The Rose Bowl, Southampton  16 Jul  15:30 IST  \n",
      "40                      Lord's Cricket Ground, London  19 Jul  15:30 IST  \n",
      "41                Riverside Ground, Chester-le-Street  22 Jul  15:30 IST  \n",
      "42                           Old Trafford, Manchester  23 Jul  15:30 IST  \n",
      "43                            Kennington Oval, London  31 Jul  15:30 IST  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import StaleElementReferenceException \n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.bcci.tv/')\n",
    "head_buttons=driver.find_elements(By.CLASS_NAME,'border-0')\n",
    "global more,body\n",
    "tours=[]\n",
    "times=[]\n",
    "ps=[]\n",
    "ds=[]\n",
    "for i in head_buttons:\n",
    "    if i.text=='Fixtures and Results':\n",
    "        i.click()\n",
    "        break\n",
    "time.sleep(7)\n",
    "upcoming=driver.find_element(By.XPATH,'//*[@id=\"fixtures\"]/div[2]/div[1]/div[2]')\n",
    "upcoming.click()\n",
    "time.sleep(10)\n",
    "more=driver.find_element(By.CLASS_NAME,'match-btn.btn-red.d-flex.align-items-center.justify-content-center.mx-auto.mt-3.morematches')\n",
    "body=driver.find_element(By.TAG_NAME,'body')\n",
    "for i in range(8):\n",
    "    try:\n",
    "        more.click()\n",
    "        time.sleep(3)\n",
    "    except StaleElementReferenceException:\n",
    "        pass\n",
    "torn_names=driver.find_elements(By.CLASS_NAME,'match-tournament-name.ng-binding')\n",
    "places=driver.find_elements(By.CLASS_NAME,'match-venue.ng-scope')\n",
    "dates=driver.find_elements(By.CLASS_NAME,'match-dates.ng-binding')\n",
    "match_times=driver.find_elements(By.CLASS_NAME,'match-time.no-margin.ng-binding')\n",
    "for t in torn_names:\n",
    "\n",
    "    tours.append(t.text)\n",
    "for p in places:\n",
    "\n",
    "    ps.append(p.text)\n",
    "for d in dates:\n",
    "\n",
    "    ds.append(d.text)\n",
    "for mt in match_times:\n",
    "    times.append(mt.text)\n",
    "\n",
    "\n",
    "df=pd.DataFrame({\n",
    "    \"Series\": tours,\n",
    "    \"Places\":ps,\n",
    "    \"Date\":ds,\n",
    "    \"Time\":times\n",
    "})\n",
    "print(df)\n",
    "df.to_csv(\"BCCI match fixtures India.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05e83ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55269d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3a721",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1918f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b14f7561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      State GSDP Latest Year GSDP (21-22) Share %  \\\n",
      "0     1                Maharashtra                -    3,108,022  13.17%   \n",
      "1     2                 Tamil Nadu        2,364,514    2,071,286   8.78%   \n",
      "2     3                  Karnataka        2,269,995    1,978,094   8.38%   \n",
      "3     4              Uttar Pradesh        2,258,040    1,975,595   8.37%   \n",
      "4     5                    Gujarat        2,230,609    1,928,683   8.17%   \n",
      "5     6                West Bengal        1,531,758    1,329,238   5.63%   \n",
      "6     7                  Rajasthan        1,365,849    1,193,489   5.06%   \n",
      "7     8             Andhra Pradesh        1,303,524    1,148,471   4.87%   \n",
      "8     9                  Telangana        1,308,034    1,124,204   4.76%   \n",
      "9    10             Madhya Pradesh        1,246,471    1,092,964   4.63%   \n",
      "10   11                     Kerala        1,046,188      934,542   3.96%   \n",
      "11   12                      Delhi        1,014,688      881,336   3.73%   \n",
      "12   13                    Haryana          984,055      868,905   3.68%   \n",
      "13   14                     Odisha          753,177      662,886   2.81%   \n",
      "14   15                      Bihar          751,396      650,302   2.76%   \n",
      "15   16                     Punjab          676,164      617,192   2.62%   \n",
      "16   17                      Assam          493,167      411,454   1.74%   \n",
      "17   18               Chhattisgarh          464,399      410,525   1.74%   \n",
      "18   19                  Jharkhand          393,722      358,863   1.52%   \n",
      "19   20                Uttarakhand          303,781      267,143   1.13%   \n",
      "20   21            Jammu & Kashmir          224,226      193,352   0.82%   \n",
      "21   22           Himachal Pradesh          191,728      172,162   0.73%   \n",
      "22   23                        Goa           93,672       84,266   0.36%   \n",
      "23   24                    Tripura           72,636       62,550   0.27%   \n",
      "24   25                 Chandigarh           54,285       46,096   0.20%   \n",
      "25   26                 Puducherry           49,643       43,810   0.19%   \n",
      "26   27                  Meghalaya           42,697       38,785   0.16%   \n",
      "27   28                     Sikkim           42,756       37,557   0.16%   \n",
      "28   29                    Manipur                -       36,594   0.16%   \n",
      "29   30          Arunachal Pradesh           39,630       34,775   0.15%   \n",
      "30   31                   Nagaland           35,643       31,038   0.13%   \n",
      "31   32                    Mizoram                -       27,824   0.12%   \n",
      "32   33  Andaman & Nicobar Islands                -       10,371   0.04%   \n",
      "33                           India       26,949,646   23,597,399           \n",
      "\n",
      "   GDP (Billions)  \n",
      "0         414.928  \n",
      "1         276.522  \n",
      "2         264.080  \n",
      "3         263.747  \n",
      "4         257.484  \n",
      "5         177.456  \n",
      "6         159.334  \n",
      "7         153.324  \n",
      "8         150.084  \n",
      "9         145.913  \n",
      "10        124.764  \n",
      "11        117.660  \n",
      "12        116.001  \n",
      "13         88.497  \n",
      "14         86.817  \n",
      "15         82.397  \n",
      "16         54.930  \n",
      "17         54.806  \n",
      "18         47.909  \n",
      "19         35.664  \n",
      "20         25.813  \n",
      "21         22.984  \n",
      "22         11.250  \n",
      "23          8.351  \n",
      "24          6.154  \n",
      "25          5.849  \n",
      "26          5.178  \n",
      "27          5.014  \n",
      "28          4.885  \n",
      "29          4.643  \n",
      "30          4.144  \n",
      "31          3.715  \n",
      "32          1.385  \n",
      "33          3,150  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://statisticstimes.com/')\n",
    "time.sleep(3)\n",
    "a = driver.find_element(By.XPATH, '//*[@id=\"top\"]/div[2]/div[2]/div/a[3]')\n",
    "first_url = a.get_attribute('href')\n",
    "driver.get(first_url)\n",
    "b = driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "second_url = b.get_attribute('href')\n",
    "driver.get(second_url)\n",
    "table = driver.find_element(By.CLASS_NAME, 'display.dataTable')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    cols = [col.text for col in cols]\n",
    "    if len(cols) >= 6:\n",
    "        data.append([cols[0], cols[1], cols[3], cols[4], cols[5], cols[6]])\n",
    "df = pd.DataFrame(data, columns=['Rank', 'State', 'GSDP Latest Year', 'GSDP (21-22)', 'Share %', 'GDP (Billions)'])\n",
    "print(df)\n",
    "df.to_csv(\"India_GDP_statewise.csv\", index=False)\n",
    "# driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb7e942",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96df80fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a5c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7492b1b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Name of repository Major language used  \\\n",
      "0                     mediar-ai / screenpipe                Rust   \n",
      "1                          exo-explore / exo              Python   \n",
      "2                        godotengine / godot                 C++   \n",
      "3                       unclecode / crawl4ai              Python   \n",
      "4                          ToolJet / ToolJet          JavaScript   \n",
      "5                           mlc-ai / web-llm          TypeScript   \n",
      "6   EbookFoundation / free-programming-books       Not Specified   \n",
      "7         dair-ai / Prompt-Engineering-Guide                 MDX   \n",
      "8                   All-Hands-AI / OpenHands              Python   \n",
      "9                           openai / whisper              Python   \n",
      "10                              pytorch / ao              Python   \n",
      "11  mainmatter / 100-exercises-to-learn-rust                Rust   \n",
      "12                github-linguist / linguist                Ruby   \n",
      "13                    continuedev / continue          TypeScript   \n",
      "14                      juspay / hyperswitch                Rust   \n",
      "15                      TheAlgorithms / Java                Java   \n",
      "16                   OpenBB-finance / OpenBB              Python   \n",
      "17               freeCodeCamp / freeCodeCamp          TypeScript   \n",
      "\n",
      "                            Description of repository Contributors  \n",
      "0   24/7 local AI screen & mic recording. Build AI...           20  \n",
      "1   Run your own AI cluster at home with everyday ...           21  \n",
      "2   Godot Engine ‚Äì Multi-platform 2D and 3D game e...        2,692  \n",
      "3   üî•üï∑Ô∏è Crawl4AI: Open-source LLM Friendly Web Cra...            9  \n",
      "4   Low-code platform for building business applic...          548  \n",
      "5    High-performance In-browser LLM Inference Engine           41  \n",
      "6                üìö Freely available programming books        2,899  \n",
      "7   üêô Guides, papers, lecture, notebooks and resou...          196  \n",
      "8                   üôå OpenHands: Code Less, Make More          189  \n",
      "9   Robust Speech Recognition via Large-Scale Weak...           69  \n",
      "10  PyTorch native quantization and sparsity for t...           68  \n",
      "11  A self-paced course to learn Rust, one exercis...           34  \n",
      "12  Language Savant. If your repository's language...        1,077  \n",
      "13  ‚è© Continue is the leading open-source AI code ...          175  \n",
      "14  An open source payments switch written in Rust...          185  \n",
      "15                 All Algorithms implemented in Java          557  \n",
      "16      Investment Research for Everyone, Everywhere.          224  \n",
      "17  freeCodeCamp.org's open-source codebase and cu...        5,000  \n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver=webdriver.Chrome()\n",
    "first_url='https://github.com/'\n",
    "driver.get(first_url)\n",
    "time.sleep(10)\n",
    "open_source=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/button')\n",
    "open_source.click()\n",
    "trending=driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[4]/div/div[3]/ul/li[2]/a')\n",
    "trending.click()\n",
    "time.sleep(5)\n",
    "all_items=driver.find_elements(By.CLASS_NAME,'Box-row')\n",
    "r_names=[]\n",
    "contris=[]\n",
    "languages=[]\n",
    "urls=[]\n",
    "descs=[]\n",
    "contri_urls=[]\n",
    "for item in all_items:\n",
    "    r_name=item.find_element(By.CLASS_NAME,'h3.lh-condensed')\n",
    "    name=r_name.text\n",
    "    r_names.append(name)\n",
    "    try:\n",
    "        language_e=item.find_element(By.CLASS_NAME,'d-inline-block.ml-0.mr-3')\n",
    "        language=language_e.text\n",
    "    except:\n",
    "        language='Not Specified'\n",
    "    languages.append(language)\n",
    "    description=item.find_element(By.CLASS_NAME,'col-9.color-fg-muted.my-1.pr-4')\n",
    "    descs.append(description.text)\n",
    "for r in r_names:\n",
    "    second_url=r.replace(' ','')\n",
    "    url=first_url+second_url\n",
    "    urls.append(url)\n",
    "for i,u in enumerate(urls):\n",
    "    driver.get(u)\n",
    "    time.sleep(5)\n",
    "    right_heads=driver.find_elements(By.CLASS_NAME,'h4.mb-3')\n",
    "    for r in right_heads:\n",
    "        x = r.text\n",
    "        a = re.match(r'Contributors\\s*([0-9]{1,3}(?:,[0-9]{3})*|\\d+)', x)\n",
    "        if a:\n",
    "            contri = re.search(r'\\d{1,3}(?:,\\d{3})*', a.group()) \n",
    "            if contri:\n",
    "                count_contri=contri.group()\n",
    "                contris.append(count_contri)\n",
    "df=pd.DataFrame({\n",
    "    \"Name of repository\":r_names,\n",
    "    \"Major language used\":languages,\n",
    "    \"Description of repository\":descs,\n",
    "    \"Contributors\":contris\n",
    "})\n",
    "print(df)\n",
    "# r_names.clear()\n",
    "# descs.clear()\n",
    "# urls.clear()\n",
    "# languages.clear()\n",
    "# contris.clear()\n",
    "# # print(contri_urls)\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e962299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011de76b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53beee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b4a8f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank        Name of song                       Artist name(s)  \\\n",
      "0     1  A Bar Song (Tipsy)                            Shaboozey   \n",
      "1     2     I Had Some Help  Post Malone Featuring Morgan Wallen   \n",
      "2     3            Espresso                    Sabrina Carpenter   \n",
      "3     4    Good Luck, Babe!                        Chappell Roan   \n",
      "4     5    Die With A Smile               Lady Gaga & Bruno Mars   \n",
      "..  ...                 ...                                  ...   \n",
      "95   96          Diet Pepsi                          Addison Rae   \n",
      "96   97         Coincidence                    Sabrina Carpenter   \n",
      "97   98     Passport Junkie                             Rod Wave   \n",
      "98   99    Circadian Rhythm                                Drake   \n",
      "99  100       Sharpest Tool                    Sabrina Carpenter   \n",
      "\n",
      "   Last week position Peak Position Weeks on Chart  \n",
      "0                   1             1             24  \n",
      "1                   2             1             20  \n",
      "2                   3             3             24  \n",
      "3                   4             4             25  \n",
      "4                   5             3              6  \n",
      "..                ...           ...            ...  \n",
      "95                 81            81              3  \n",
      "96                 73            26              5  \n",
      "97                 61            61              2  \n",
      "98                 66            59              4  \n",
      "99                 76            21              5  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import selenium\n",
    "import pandas\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "driver=webdriver.Chrome()\n",
    "driver.get('https://www.billboard.com/')\n",
    "charts=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "charts.click()\n",
    "time.sleep(10)\n",
    "top_100=driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[3]/div/nav/ul/li[1]/a')\n",
    "top_100.click()\n",
    "all_items=driver.find_elements(By.CLASS_NAME,'o-chart-results-list-row-container')\n",
    "ranks=[]\n",
    "names=[]\n",
    "artist_names=[]\n",
    "weeks=[]\n",
    "peaks=[]\n",
    "lasts=[]\n",
    "\n",
    "for item in all_items:\n",
    "    text=item.text\n",
    "    words=re.split(r'\\n',text)\n",
    "    if words[1]==\"NEW\" or words[1]==\"RE- ENTRY\":\n",
    "        words[1]=words[2]\n",
    "        words[2]=words[3]\n",
    "        words[3]=words[4]\n",
    "        words[4]=words[5]\n",
    "        words[5]=words[6]\n",
    "\n",
    "    rank=words[0]\n",
    "    ranks.append(rank)\n",
    "    name=words[1]\n",
    "    names.append(name)\n",
    "    artist_name=words[2]\n",
    "    artist_names.append(artist_name)\n",
    "    last=words[3]\n",
    "    lasts.append(last)\n",
    "    peak=words[4]\n",
    "    peaks.append(peak)\n",
    "    week=words[5]\n",
    "    weeks.append(week)\n",
    "df=pd.DataFrame({\n",
    "    \"Rank\":ranks,\n",
    "    \"Name of song\":names,\n",
    "    \"Artist name(s)\":artist_names,\n",
    "    \"Last week position\":lasts,\n",
    "    \"Peak Position\":peaks,\n",
    "    \"Weeks on Chart\":weeks\n",
    "})\n",
    "\n",
    "print(df)\n",
    "df.to_csv(\"Billboard top 100.csv\")\n",
    "# driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db57ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169f77b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f989f874",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9063f55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Rank                                          Book Name       Author Name  \\\n",
      "1      1                                  Da Vinci Code,The        Brown, Dan   \n",
      "2      2               Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
      "3      3           Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
      "4      4          Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
      "5      5                               Fifty Shades of Grey      James, E. L.   \n",
      "..   ...                                                ...               ...   \n",
      "96    96                                          Ghost,The    Harris, Robert   \n",
      "97    97                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
      "98    98              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
      "99    99  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
      "100  100  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
      "\n",
      "    Volumes Sold        Publisher                        Genre  \n",
      "1      5,094,805       Transworld  Crime, Thriller & Adventure  \n",
      "2      4,475,152       Bloomsbury           Children's Fiction  \n",
      "3      4,200,654       Bloomsbury           Children's Fiction  \n",
      "4      4,179,479       Bloomsbury           Children's Fiction  \n",
      "5      3,758,936     Random House              Romance & Sagas  \n",
      "..           ...              ...                          ...  \n",
      "96       807,311     Random House   General & Literary Fiction  \n",
      "97       794,201          Penguin        Food & Drink: General  \n",
      "98       792,187  Scholastic Ltd.          Young Adult Fiction  \n",
      "99       791,507            Orion           Biography: General  \n",
      "100      791,095          Penguin        Food & Drink: General  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "time.sleep(3)\n",
    "table = driver.find_element(By.CLASS_NAME, 'in-article.sortable')\n",
    "rows = table.find_elements(By.TAG_NAME, 'tr')\n",
    "data = []\n",
    "for row in rows:\n",
    "    cols = row.find_elements(By.TAG_NAME, 'td')\n",
    "    if cols:\n",
    "        data.append([col.text for col in cols])\n",
    "df = pd.DataFrame(data)\n",
    "df = df.iloc[1:]\n",
    "df.columns = [\"Rank\", \"Book Name\", \"Author Name\", \"Volumes Sold\", \"Publisher\", \"Genre\"]\n",
    "df.to_csv(\"Top 100 selling books.csv\", index=False)\n",
    "# driver.quit()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97530515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cb676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "595ece18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7 page not found so was advised to skip as per ticket Id #23059,  https://www.flipnwork.com/index.php/tickets/view/23059"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0541829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddfe6268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   Name  \\\n",
      "0                                  Iris   \n",
      "1                         Heart Disease   \n",
      "2                          Wine Quality   \n",
      "3                                 Adult   \n",
      "4  Breast Cancer Wisconsin (Diagnostic)   \n",
      "5                        Bank Marketing   \n",
      "6                                  Wine   \n",
      "7                   Student Performance   \n",
      "8                         Online Retail   \n",
      "9                        Car Evaluation   \n",
      "\n",
      "                 Dataset Characteristics            Associated Tasks  \\\n",
      "0                                Tabular              Classification   \n",
      "1                           Multivariate              Classification   \n",
      "2                           Multivariate  Classification, Regression   \n",
      "3                           Multivariate              Classification   \n",
      "4                           Multivariate              Classification   \n",
      "5                           Multivariate              Classification   \n",
      "6                                Tabular              Classification   \n",
      "7                           Multivariate  Classification, Regression   \n",
      "8  Multivariate, Sequential, Time-Series  Classification, Clustering   \n",
      "9                           Multivariate              Classification   \n",
      "\n",
      "                 Feature Type # Instances # Features  Year  \n",
      "0                        Real         150          4  1988  \n",
      "1  Categorical, Integer, Real         303         13  1988  \n",
      "2                        Real        4898         11  2009  \n",
      "3        Categorical, Integer       48842         14  1996  \n",
      "4                        Real         569         30  1995  \n",
      "5        Categorical, Integer       45211         16  2012  \n",
      "6               Integer, Real         178         13  1991  \n",
      "7                     Integer         649         30  2014  \n",
      "8               Integer, Real      541909          6  2015  \n",
      "9                 Categorical        1728          6  1997  \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "driver = webdriver.Chrome()\n",
    "driver.get('https://archive.ics.uci.edu/')\n",
    "driver.maximize_window()\n",
    "head_items = driver.find_elements(By.XPATH, '/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a')\n",
    "for h in head_items:\n",
    "    if h.text == 'Datasets':\n",
    "        datasets_url = h.get_attribute('href')\n",
    "        driver.get(datasets_url)\n",
    "        break\n",
    "time.sleep(5)\n",
    "header = driver.find_elements(By.CLASS_NAME, 'swap')\n",
    "for h in header:\n",
    "    if h.text == \"Expand All\":\n",
    "        h.click()\n",
    "        break\n",
    "time.sleep(5)\n",
    "items = driver.find_elements(By.CLASS_NAME, 'rounded-box.bg-base-100')\n",
    "names = []\n",
    "urls = []\n",
    "for item in items[3:]:\n",
    "    try:\n",
    "        name = WebDriverWait(item, 10).until(\n",
    "            EC.presence_of_element_located((By.CLASS_NAME, 'truncate.text-primary'))).text\n",
    "        url_element = item.find_element(By.TAG_NAME, 'a')\n",
    "        url = url_element.get_attribute('href')\n",
    "        names.append(name)\n",
    "        urls.append(url)\n",
    "    except:\n",
    "        pass\n",
    "dataset_characteristics_list = []\n",
    "associated_tasks_list = []\n",
    "feature_type_list = []\n",
    "num_instances_list = []\n",
    "num_features_list = []\n",
    "year_list = []\n",
    "for u in urls:\n",
    "    driver.get(u)\n",
    "    time.sleep(3)\n",
    "\n",
    "    try:\n",
    "        dataset_details = driver.find_elements(By.CLASS_NAME, 'col-span-4')\n",
    "        \n",
    "        dataset_characteristics = \"\"\n",
    "        associated_tasks = \"\"\n",
    "        feature_type = \"\"\n",
    "        num_instances = \"\"\n",
    "        num_features = \"\"\n",
    "        year = \"\"\n",
    "\n",
    "        for detail in dataset_details:\n",
    "            heading = detail.find_element(By.TAG_NAME, 'h1').text\n",
    "            value = detail.find_element(By.TAG_NAME, 'p').text\n",
    "\n",
    "            if heading == \"Dataset Characteristics\":\n",
    "                dataset_characteristics = value\n",
    "            elif heading == \"Associated Tasks\":\n",
    "                associated_tasks = value\n",
    "            elif heading == \"Feature Type\":\n",
    "                feature_type = value\n",
    "            elif heading == \"# Instances\":\n",
    "                num_instances = value\n",
    "            elif heading == \"# Features\":\n",
    "                num_features = value\n",
    "        try:\n",
    "            year_element = driver.find_element(By.CLASS_NAME, 'text-sm.text-primary-content')\n",
    "            year_text = year_element.text\n",
    "            year = year_text.split('/')[-1]\n",
    "        except:\n",
    "            year = \"Unknown\"\n",
    "        dataset_characteristics_list.append(dataset_characteristics)\n",
    "        associated_tasks_list.append(associated_tasks)\n",
    "        feature_type_list.append(feature_type)\n",
    "        num_instances_list.append(num_instances)\n",
    "        num_features_list.append(num_features)\n",
    "        year_list.append(year)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while extracting data for {u}: {e}\")\n",
    "df = pd.DataFrame({\n",
    "    'Name': names,\n",
    "    'Dataset Characteristics': dataset_characteristics_list,\n",
    "    'Associated Tasks': associated_tasks_list,\n",
    "    'Feature Type': feature_type_list,\n",
    "    '# Instances': num_instances_list,\n",
    "    '# Features': num_features_list,\n",
    "    'Year': year_list\n",
    "})\n",
    "df.to_csv(\"datasets_info.csv\", index=False)\n",
    "# driver.quit()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2c12d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
